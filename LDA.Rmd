# LDA 


Measure perplexity in our trained LDA.
(Use perplexity and CV to choose k)
  
```{r load dataset}
# load functions for LDA analysis
source("LDA/lda_functions.R")

# Load dataset with lemmatized words
corpus_ita <- read.csv("csv/cleaned_svevo_dataset_ITA.csv", sep=",", encoding = "UTF-8")

```

```{r evaluate perplexity and coherence, eval=FALSE}
# take a lot of time !!!
perplexity_lda <- evaluate_perplexity(corpus_ita, save_results = TRUE)

coherence_lda <- evaluate_coherence(kmax = 50, corpus_ita, save_results = TRUE)

```

```{r plot perplexity and coherence}
perplexity_lda <- read.csv("csv/perplexity.csv")

ggplot(perplexity_lda, aes(x = k, y = perplexity)) +
  geom_point() +
  geom_smooth(se = FALSE) +
  ggtitle("5-fold cross-validation of topic modelling",
          "(The points represent five different models fit for each candidate number of topics)") +
  labs(x = "K", y = "Perplexity when fitting the trained model to the hold-out set")

#ggsave("plots/perplexity.png", width = 20, height = 8, dpi = 150)

coherence_lda <- read.csv("csv/coherence.csv")
colnames(coherence_lda) <- c("k", "coherence")

ggplot(coherence_lda) +
  geom_point(aes(x = 5, y = coherence_lda$coherence[5]), col = "red", size = 3) +
  geom_line(aes(x = k, y = coherence), col = "violet") + 
  xlab("K") + 
  ylab("Coherence")

#ggsave("plots/coherence.png", width = 20, height = 8, dpi = 150)

```
```{r plot silhouette}
silhouette_lda <- read.csv("csv/silhouette.csv")

ggplot(silhouette_lda, aes(x = X, y = x)) +
  geom_point() +
  geom_point(aes(x = 5, y = silhouette_lda$x[5]), col = "red") +
  geom_smooth(se = FALSE) +
  labs(x = "K", y = "silhouette score")

#ggsave("plots/silhouette.png", width = 20, height = 8, dpi = 150)
```




# Main Topics analysis

An analysis of suitable value for the number of topics k is provided in `LDA.R`.
We choose an intermediate value for k, which ensures a good coherence between topics
while keeping perplexity low.

Build LDA model with a suitable value for k.
```{r build lda model, eval=FALSE, include=FALSE}
lda_model_ita <- one_model_analysis(num_topics = 5, corpus_ita, save_results = TRUE)
```

Load pre-trained LDA model

```{r }
lda_model_ita <- readRDS("LDA/LDA_corpus_topic_model.rds")
```

Analysis of main topics obtained.
```{r}
#print summary table
lda_model_ita$summary[ order(lda_model_ita$summary$prevalence, decreasing = TRUE) , ]
SummarizeTopics(lda_model_ita)

```




Analyze how topics evolved over time:

```{r}
#input: one topic
#output: its trend over time

# obtain document-topic probabilities -> lda_ita2$theta
# number are those of italian letters in the original corpus

topic_time <- topic_trend_over_time(corpus_ita, lda_model_ita)

```

```{r plot topic trend over time}
library(dplyr)
library(ggplot2)
library(tidyr)


sum_topic <- topic_time %>%
  group_by(date) %>%
  summarise(across(everything(), sum))

sum_topic  %>%
    gather(key,value, t_1, t_2, t_3, t_4, t_5) %>%
    ggplot() +
    geom_line(aes(x=date, y=value, colour=key, group = 1),ylab="")+
    geom_point(aes(x=date, y=value, colour=key, group = 1),ylab="")

```

```{r plot topic over time and person for document}
topic_trend_over_people_for_document(lda_model_ita, corpus_ita)
topic_trend_over_time_for_document(lda_model_ita, corpus_ita)
```

